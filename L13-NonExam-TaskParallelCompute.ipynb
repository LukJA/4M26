{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98da2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "FORMAT = '[%(name)s:%(levelname)s]  %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=FORMAT)\n",
    "logger = logging.getLogger('dbg')\n",
    "\n",
    "def dprint(s):\n",
    "    logger.debug(s)\n",
    "\n",
    "def iprint(s):\n",
    "    logger.info(s)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a21ebdce",
   "metadata": {},
   "source": [
    "## Task Parallel Compute\n",
    "\n",
    "**Moore's Law** - 1965: double every year for minimum component cost\n",
    "**Moore's Law** - 1975: double every two years\n",
    "\n",
    "### Dennard Scaling\n",
    "\n",
    "With each generation, transistor dimensions shrink by 30%:\n",
    "- Double the # of devices\n",
    "- Same power\n",
    "- 40% faster\n",
    "\n",
    "Ended in around 2005 as the model ignores leakage current\n",
    "\n",
    "### Amdahl's Law for Speed-up\n",
    "\n",
    "Let $\\alpha \\in [0, 1]$ be the fraction of code that can be parallelized fully. Let $P$ be the number of processors and $T$ be time:\n",
    "\n",
    "$T_{new} = T \\times \\left ( (1 - \\alpha) \\frac{\\alpha }{P} \\right)$\n",
    "\n",
    "Amdahl's law is a loose **Upper Bound** on parallelism efficiency, i.e. its usually worse\n",
    "\n",
    "### Gustafson's Law\n",
    "Amdahl's law is based on the assumption of a fixed problem size, that is of an execution workload that does not change with respect to the improvement of the resources. \n",
    "\n",
    "Gustafson's law instead proposes that programmers tend to increase the size of problems to fully exploit the computing power that becomes available as the resources improve.\n",
    "\n",
    "Speed-Up = $1 + \\alpha \\cdot (P -1)$ - Linear Scaling with P!\n",
    "\n",
    "The correct law depends on the system and the task at hand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bbbf05f",
   "metadata": {},
   "source": [
    "### Memory Models For Parallel Computing\n",
    "\n",
    "How to organise multi-core memory?\n",
    "\n",
    "**Distributed Memory**\n",
    "* Each core requests the memory of another core over a network\n",
    "\n",
    "**Shared Memory**\n",
    "* Any core can access any memory in a shared address space\n",
    "* **SMP** Uniform Memory Access (UMA)\n",
    "    * uniform access time to all memory\n",
    "* **DSM** Non Uniform Memory Access (NUMA)\n",
    "    * access time depends on location of data and network topology\n",
    "\n",
    "\n",
    "### Parallelism\n",
    "\n",
    "**Data-level**\n",
    "* Processors perform the same task on different subsets of data in parallel\n",
    "\n",
    "**Task level**\n",
    "* Distribute tasks across processors - different tasks may be run on the same data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5958d0cd",
   "metadata": {},
   "source": [
    "### Task level Parallelism\n",
    "\n",
    "Task parallelism can be implemented with, threads (\"virtual processors\") that share memory. However, this has proven difficult to program: Scheduling/load-balancing is a challenging job.\n",
    "\n",
    "**Task-parallel platforms** Add an abstraction layer on top of threads. Programmer specifies which tasks can run in parallel (but not where they run). Platform manages scheduling, balancing etc.\n",
    "\n",
    "#### Fork Join\n",
    "\n",
    "Most task-parallel platforms support fork-join:\n",
    "* **Spawn: \"forks\"** - executes function while caller continues to run in parallel\n",
    "* **Sync: \"joins\"** - waits for spawned threads to finish before proceeding\n",
    "\n",
    "Key concept: programmer only specifies which tasks can run in parallel, not which tasks must run in parallel. Parallel sections can fork recursively until reaching a given task granularity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e48be903",
   "metadata": {},
   "source": [
    "### Parallel Computation Analysis\n",
    "\n",
    "Assume:\n",
    "* We have an ideal parallel computer\n",
    "    * Multiple Cores\n",
    "    * Sequentially consistent memory model\n",
    "    * Uniform Compution power\n",
    "* There is no scheduling overhead\n",
    "\n",
    "#### Work-Span\n",
    "\n",
    "Let $T_P$ denote the runtime on $P$ processors\n",
    "* **Work** - $T_1$ - time to execute on 1 core\n",
    "* **Span** - $T_\\infty$ - time to execute on $\\infty$ cores\n",
    "\n",
    "The **span** is the sum of runtime of strands on the 'critical path' - the longest path in the computational DAG.\n",
    "\n",
    "1. **Work Law** $\\rightarrow T_P \\geq T_1 / P$ \n",
    "1. **Span Law** $\\rightarrow T_P \\geq T_\\infty$ \n",
    "1. **Speedup** $\\rightarrow T_1 / T_P$ \n",
    "1. **Lin Speedup** $\\rightarrow T_1 / T_P = \\Theta(P)$ \n",
    "1. **Parallelism** $\\rightarrow T_1 / T_\\infty$ (Max possible speedup) \n",
    "\n",
    "Parallel analysis can then be performed on an algorithm:\n",
    "\n",
    "<img src=\"media/workspan.png\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e36e3e6b",
   "metadata": {},
   "source": [
    "Find **Work** $\\mathbb{W} = T_1(n)$ and **Span** $\\mathbb{S} = T_\\infty(n)$\n",
    "\n",
    "Parallelism = $\\mathbb{W}/\\mathbb{S} = T_1(n) / T_\\infty(n)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
